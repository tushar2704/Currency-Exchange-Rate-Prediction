{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#F5DEB3;\n           font-size:170%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n<p style=\"padding: 10px;\n          text-align: center;\n          font-size:150%;\n          color:blue;\">\n           ðŸ’³ðŸ¤–Credit Card Approvals with and w/o Auto MLðŸ’³ðŸ¤–\n            \n</p>\n<style>\n        h1{text-align: center;}\n</style>  \n    \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:cursive; font-size:15px; color:'darkcyan';\">I brewed this notebook from scratch, If this notebook helped, please consider upvoting and cite me if sharing ,Thank you!</p>\nâ€‹\n<p style=\"width: 700px;padding: 15px;background: papayawhip;border-radius:10px;font-size:15px;border-radius:20px\">\n    <a href=\"https://www.linkedin.com/in/tusharaggarwalinseec/\" target=\"_blank\">Lets connect on LinkedIn!</a>\n    \n   </p>\n<p style=\"width: 700px;padding: 15px;background: papayawhip;border-radius:10px;font-size:15px;border-radius:20px\">\n<a href=\"https://github.com/tushar2704\" target=\"_blank\">Follow me on Github too!</a> </p>\n<p style=\"width: 700px;padding: 15px;background: papayawhip;border-radius:10px;font-size:15px;border-radius:20px\">\n    <a href=\"https://medium.com/@tushar_aggarwal\" target=\"_blank\">Also checkout my Medium posts!</a>\n    \n   </p>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:17px;border-radius:20px\">\n    <b>In this project, I am building a machine learning model to predict if a credit card application will get approved.</b>\n    \n</div>\n<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:20px;border-radius:20px\">\n    <b>This projectis in 2 parts\n    <br>1.Without Auto ML (PyCaret)\n        <br>2.With Auto ML (PyCaret)</b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">\n    <b><b>1.Without Auto ML (PyCaret)</b></b>\n    \n   </p>\n<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:17px;border-radius:20px\">\n    <b>Credit card applications</b>\n    \n</div>\n<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">\n    <b>Some thing to note:</b>\n    <br><br>&#8226; Commercial banks receive a lot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. \n    <br>&#8226; Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!).\n   </p>\n   \n<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\"> \n1.     &#8226; Using the Credit Card Approval dataset from the UCI Machine Learning Repository, whcih has 2 seprate dataset<br>\n    <a href=\"https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\" target=\"_blank\">Click here for dataset</a>\n\n\n   ","metadata":{}},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Importing the required Libraries\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"#Importing the basic liabraries\nimport numpy as np\nimport pandas as pd\n\n#Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.104914Z","iopub.execute_input":"2023-01-19T11:53:23.105445Z","iopub.status.idle":"2023-01-19T11:53:23.113217Z","shell.execute_reply.started":"2023-01-19T11:53:23.105402Z","shell.execute_reply":"2023-01-19T11:53:23.111483Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Loading the data\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Loading the dataset\ncc_data = pd.read_csv(\"/kaggle/input/cc-approvals/cc_approvals.data\", header=None)\n\n# Inspecting data\nprint(cc_data)\n\n#to Dataframe\ncc_data=pd.DataFrame(cc_data)\ncc_data","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.125084Z","iopub.execute_input":"2023-01-19T11:53:23.125615Z","iopub.status.idle":"2023-01-19T11:53:23.182003Z","shell.execute_reply.started":"2023-01-19T11:53:23.125573Z","shell.execute_reply":"2023-01-19T11:53:23.180526Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"    0      1       2  3  4   5   6     7  8  9   10 11 12     13   14 15\n0    b  30.83   0.000  u  g   w   v  1.25  t  t   1  f  g  00202    0  +\n1    a  58.67   4.460  u  g   q   h  3.04  t  t   6  f  g  00043  560  +\n2    a  24.50   0.500  u  g   q   h  1.50  t  f   0  f  g  00280  824  +\n3    b  27.83   1.540  u  g   w   v  3.75  t  t   5  t  g  00100    3  +\n4    b  20.17   5.625  u  g   w   v  1.71  t  f   0  f  s  00120    0  +\n..  ..    ...     ... .. ..  ..  ..   ... .. ..  .. .. ..    ...  ... ..\n685  b  21.08  10.085  y  p   e   h  1.25  f  f   0  f  g  00260    0  -\n686  a  22.67   0.750  u  g   c   v  2.00  f  t   2  t  g  00200  394  -\n687  a  25.25  13.500  y  p  ff  ff  2.00  f  t   1  t  g  00200    1  -\n688  b  17.92   0.205  u  g  aa   v  0.04  f  f   0  f  g  00280  750  -\n689  b  35.00   3.375  u  g   c   h  8.29  f  f   0  t  g  00000    0  -\n\n[690 rows x 16 columns]\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"    0      1       2  3  4   5   6     7  8  9   10 11 12     13   14 15\n0    b  30.83   0.000  u  g   w   v  1.25  t  t   1  f  g  00202    0  +\n1    a  58.67   4.460  u  g   q   h  3.04  t  t   6  f  g  00043  560  +\n2    a  24.50   0.500  u  g   q   h  1.50  t  f   0  f  g  00280  824  +\n3    b  27.83   1.540  u  g   w   v  3.75  t  t   5  t  g  00100    3  +\n4    b  20.17   5.625  u  g   w   v  1.71  t  f   0  f  s  00120    0  +\n..  ..    ...     ... .. ..  ..  ..   ... .. ..  .. .. ..    ...  ... ..\n685  b  21.08  10.085  y  p   e   h  1.25  f  f   0  f  g  00260    0  -\n686  a  22.67   0.750  u  g   c   v  2.00  f  t   2  t  g  00200  394  -\n687  a  25.25  13.500  y  p  ff  ff  2.00  f  t   1  t  g  00200    1  -\n688  b  17.92   0.205  u  g  aa   v  0.04  f  f   0  f  g  00280  750  -\n689  b  35.00   3.375  u  g   c   h  8.29  f  f   0  t  g  00000    0  -\n\n[690 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00202</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00043</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00280</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00100</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>00120</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>b</td>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>y</td>\n      <td>p</td>\n      <td>e</td>\n      <td>h</td>\n      <td>1.25</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00260</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>a</td>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>2.00</td>\n      <td>f</td>\n      <td>t</td>\n      <td>2</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00200</td>\n      <td>394</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>a</td>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>2.00</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00200</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>b</td>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.04</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>00280</td>\n      <td>750</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>b</td>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>8.29</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>00000</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n<p>690 rows Ã— 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Inspecting the applications\n    \n   </p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">The features of this dataset have been anonymized to protect the privacy, but the probable features in a typical credit card application are Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and finally the ApprovalStatus.\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"#printing the summary statistics\nprint(cc_data.describe())\nprint(\"/n\")\n\nprint(cc_data.info())\nprint('/n')\n\nprint(cc_data.tail(11))","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.184139Z","iopub.execute_input":"2023-01-19T11:53:23.184531Z","iopub.status.idle":"2023-01-19T11:53:23.227344Z","shell.execute_reply.started":"2023-01-19T11:53:23.184496Z","shell.execute_reply":"2023-01-19T11:53:23.226174Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"               2           7          10             14\ncount  690.000000  690.000000  690.00000     690.000000\nmean     4.758725    2.223406    2.40000    1017.385507\nstd      4.978163    3.346513    4.86294    5210.102598\nmin      0.000000    0.000000    0.00000       0.000000\n25%      1.000000    0.165000    0.00000       0.000000\n50%      2.750000    1.000000    0.00000       5.000000\n75%      7.207500    2.625000    3.00000     395.500000\nmax     28.000000   28.500000   67.00000  100000.000000\n/n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 690 entries, 0 to 689\nData columns (total 16 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       690 non-null    object \n 1   1       690 non-null    object \n 2   2       690 non-null    float64\n 3   3       690 non-null    object \n 4   4       690 non-null    object \n 5   5       690 non-null    object \n 6   6       690 non-null    object \n 7   7       690 non-null    float64\n 8   8       690 non-null    object \n 9   9       690 non-null    object \n 10  10      690 non-null    int64  \n 11  11      690 non-null    object \n 12  12      690 non-null    object \n 13  13      690 non-null    object \n 14  14      690 non-null    int64  \n 15  15      690 non-null    object \ndtypes: float64(2), int64(2), object(12)\nmemory usage: 86.4+ KB\nNone\n/n\n    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Splitting the dataset into train and test sets\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Drop the features 11 and 13 as they are 'DriversLicense' and 'ZipCode'\ncc_data = cc_data.drop([11,13], axis=1)\n\n# Splitting into train and test sets\ncc_data_train, cc_data_test = train_test_split(cc_data, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.229067Z","iopub.execute_input":"2023-01-19T11:53:23.229901Z","iopub.status.idle":"2023-01-19T11:53:23.239358Z","shell.execute_reply.started":"2023-01-19T11:53:23.229848Z","shell.execute_reply":"2023-01-19T11:53:23.238257Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Handling the missing values\n    \n   </p>\n   \n   \n  <p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">\n   The features 2, 7, 10 and 14 contain numeric values (of types float64, float64, int64 and int64 respectively) and all the other features contain non-numeric values.</p>","metadata":{}},{"cell_type":"code","source":"# Replacing the '?'s with NaN in the train and test sets\ncc_data_train = cc_data_train.replace(\"?\", np.NaN)\ncc_data_test = cc_data_test.replace(\"?\", np.NaN)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.242841Z","iopub.execute_input":"2023-01-19T11:53:23.243881Z","iopub.status.idle":"2023-01-19T11:53:23.263430Z","shell.execute_reply.started":"2023-01-19T11:53:23.243822Z","shell.execute_reply":"2023-01-19T11:53:23.262423Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# Imputing the missing values with mean imputation\ncc_data_train.fillna(cc_data_train.mean(), inplace=True)\ncc_data_test.fillna(cc_data_test.mean(), inplace=True)\n\n# Counting the number of NaNs in the datasets and print the counts to verify if none arepresent now\ncc_data_train.isna().sum()\ncc_data_test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.265277Z","iopub.execute_input":"2023-01-19T11:53:23.266150Z","iopub.status.idle":"2023-01-19T11:53:23.297817Z","shell.execute_reply.started":"2023-01-19T11:53:23.266093Z","shell.execute_reply":"2023-01-19T11:53:23.296178Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"0     4\n1     7\n2     0\n3     0\n4     0\n5     2\n6     2\n7     0\n8     0\n9     0\n10    0\n12    0\n14    0\n15    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#For Categorical dtypes\n\n\nfor col in cc_data_train:\n    # Checking if the column is of object type\n    if cc_data_train[col].dtypes == 'object':\n        # Imputing with the most frequent value\n        cc_data_train = cc_data_train.fillna(cc_data_train[col].value_counts().index[0])\n        cc_data_test = cc_data_test.fillna(cc_data_test[col].value_counts().index[0])\n\n# Counting the number of NaNs in the dataset and print the counts to verify none left overall now\nprint(cc_data_train.isnull().sum())\nprint(cc_data_test.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.300415Z","iopub.execute_input":"2023-01-19T11:53:23.300847Z","iopub.status.idle":"2023-01-19T11:53:23.362939Z","shell.execute_reply.started":"2023-01-19T11:53:23.300809Z","shell.execute_reply":"2023-01-19T11:53:23.360856Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     0\n9     0\n10    0\n12    0\n14    0\n15    0\ndtype: int64\n0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     0\n9     0\n10    0\n12    0\n14    0\n15    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\"> Preprocessing the data\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Converting the categorical features in the train and test sets independently, next if required with OneHotEncoder\ncc_data_train = pd.get_dummies(cc_data_train)\ncc_data_test = pd.get_dummies(cc_data_test)\n\n# Reindexing the columns of the test set aligning with the train set\ncc_data_test = cc_data_test.reindex(columns=cc_data_train.columns, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.364748Z","iopub.execute_input":"2023-01-19T11:53:23.365147Z","iopub.status.idle":"2023-01-19T11:53:23.402625Z","shell.execute_reply.started":"2023-01-19T11:53:23.365114Z","shell.execute_reply":"2023-01-19T11:53:23.400965Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# Scaling with MinMaxScaler\n\n# Segregating features and labels into separate variables\nX_train, y_train = cc_data_train.iloc[:,:-1].values, cc_data_train.iloc[:,[-1]].values\nX_test, y_test = cc_data_test.iloc[:,:-1].values, cc_data_test.iloc[:,[-1]].values\n\n# Instantiating MinMaxScaler and use it to rescale X_train and X_test\nscaler = MinMaxScaler(feature_range=(0,1))\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.405313Z","iopub.execute_input":"2023-01-19T11:53:23.405926Z","iopub.status.idle":"2023-01-19T11:53:23.424889Z","shell.execute_reply.started":"2023-01-19T11:53:23.405877Z","shell.execute_reply":"2023-01-19T11:53:23.423389Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\"> Fitting a logistic regression model to the train set\n    \n   </p>\n   \n<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\"> Out of 690 instances, there are 383 (55.5%) applications that got denied and 307 (44.5%) applications that got approved and asumption is that features are correlated\n   </p>","metadata":{}},{"cell_type":"code","source":"# Instantiating a LogisticRegression classifier with default parameter values(tol, max_iter)\nlogreg = LogisticRegression()\n\n# Fit logreg to the train set\nlogreg.fit(rescaledX_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.429191Z","iopub.execute_input":"2023-01-19T11:53:23.430122Z","iopub.status.idle":"2023-01-19T11:53:23.488906Z","shell.execute_reply.started":"2023-01-19T11:53:23.430070Z","shell.execute_reply":"2023-01-19T11:53:23.487000Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Making predictions and evaluating performance\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Using logreg to predict instances from the test set and store it\ny_pred = logreg.predict(rescaledX_test)\n\n# Getting the accuracy score of logreg model and printing it\nprint(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n\n# Printing the confusion matrix of the logreg model\nprint(confusion_matrix(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.491123Z","iopub.execute_input":"2023-01-19T11:53:23.491883Z","iopub.status.idle":"2023-01-19T11:53:23.514147Z","shell.execute_reply.started":"2023-01-19T11:53:23.491819Z","shell.execute_reply":"2023-01-19T11:53:23.512686Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Accuracy of logistic regression classifier:  1.0\n[[103   0]\n [  0 125]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Grid searching and making the model perform so maybe it wont overfit, its aleady \"1.0\" ðŸ˜²\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Defining the grid of values for hyperparameters tol and max_iter\ntol = [0.01, 0.001,0.0001]\nmax_iter = [100, 150 ,200]\n\n# Creating a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\nparam_grid = dict(tol=tol, max_iter=max_iter)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.516106Z","iopub.execute_input":"2023-01-19T11:53:23.517360Z","iopub.status.idle":"2023-01-19T11:53:23.525194Z","shell.execute_reply.started":"2023-01-19T11:53:23.517280Z","shell.execute_reply":"2023-01-19T11:53:23.523418Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">Finding the best performing model\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"# Instantiating GridSearchCV with the required parameters\ngrid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n\n# Fit grid_model to the data\ngrid_model_result = grid_model.fit(rescaledX_train, y_train)\n\n# Summarize results\nbest_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_score, best_params))\n\n# Extract the best model and evaluate it on the test set\nbest_model = grid_model_result.best_estimator_\nprint(\"Accuracy of logistic regression classifier: \", best_model)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:23.527449Z","iopub.execute_input":"2023-01-19T11:53:23.528921Z","iopub.status.idle":"2023-01-19T11:53:24.872002Z","shell.execute_reply.started":"2023-01-19T11:53:23.528859Z","shell.execute_reply":"2023-01-19T11:53:24.870668Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":114,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}\nAccuracy of logistic regression classifier:  LogisticRegression(tol=0.01)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<p style=\"width: 1000px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\">ðŸ’³ðŸ¤–Cool , as this was sliced data from original,this worked so well here, next with AutoML with different data source but same project/target, lets see the performance!ðŸ’³ðŸ¤–\n    \n   </p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">\n    <b><b>2.With Auto ML (PyCaret)</b></b>\n    \n   </p>\n<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:17px;border-radius:20px\">\n    <b>Credit card applications</b>","metadata":{}},{"cell_type":"code","source":"#Loading dataset in to pd DataFrame\n#app_data is the Application dataset, while credit_score is Credit score extarcted from credit bureau(Equifax, Experian, and TransUnion.)\n\napp_data=pd.read_csv(\"/kaggle/input/credit-card-approval-prediction/application_record.csv\")\ncredit_score=pd.read_csv(\"/kaggle/input/credit-card-approval-prediction/credit_record.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:24.873808Z","iopub.execute_input":"2023-01-19T11:53:24.874680Z","iopub.status.idle":"2023-01-19T11:53:26.170140Z","shell.execute_reply.started":"2023-01-19T11:53:24.874627Z","shell.execute_reply":"2023-01-19T11:53:26.168930Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"#Checking for loaded datasets\nprint(app_data.head()), print(credit_score.head())","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:26.172008Z","iopub.execute_input":"2023-01-19T11:53:26.172939Z","iopub.status.idle":"2023-01-19T11:53:26.193870Z","shell.execute_reply.started":"2023-01-19T11:53:26.172877Z","shell.execute_reply":"2023-01-19T11:53:26.192321Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n0  5008804           M            Y               Y             0   \n1  5008805           M            Y               Y             0   \n2  5008806           M            Y               Y             0   \n3  5008808           F            N               Y             0   \n4  5008809           F            N               Y             0   \n\n   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n0          427500.0               Working               Higher education   \n1          427500.0               Working               Higher education   \n2          112500.0               Working  Secondary / secondary special   \n3          270000.0  Commercial associate  Secondary / secondary special   \n4          270000.0  Commercial associate  Secondary / secondary special   \n\n     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n0        Civil marriage   Rented apartment      -12005          -4542   \n1        Civil marriage   Rented apartment      -12005          -4542   \n2               Married  House / apartment      -21474          -1134   \n3  Single / not married  House / apartment      -19110          -3051   \n4  Single / not married  House / apartment      -19110          -3051   \n\n   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n0           1                1           0           0             NaN   \n1           1                1           0           0             NaN   \n2           1                0           0           0  Security staff   \n3           1                0           1           1     Sales staff   \n4           1                0           1           1     Sales staff   \n\n   CNT_FAM_MEMBERS  \n0              2.0  \n1              2.0  \n2              2.0  \n3              1.0  \n4              1.0  \n        ID  MONTHS_BALANCE STATUS\n0  5001711               0      X\n1  5001711              -1      0\n2  5001711              -2      0\n3  5001711              -3      0\n4  5001712               0      C\n","output_type":"stream"},{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:20px;border-radius:20px\"><b>Inspecting the applications</b>\n    \n   </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">&#8226; As the features of this dataset have been anonymized to protect the privacy,\n    <br>&#8226; The probable features in a typical credit card application are Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and finally the ApprovalStatus.\n    <br>\n\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"#Printing the Summary Statistics\n\nprint(app_data.describe())\nprint(\"/n\")\n\nprint(app_data.info())\nprint(\"/n\")\n\nprint(app_data.tail(11))","metadata":{"execution":{"iopub.status.busy":"2023-01-19T11:53:26.195660Z","iopub.execute_input":"2023-01-19T11:53:26.196184Z","iopub.status.idle":"2023-01-19T11:53:26.544131Z","shell.execute_reply.started":"2023-01-19T11:53:26.196133Z","shell.execute_reply":"2023-01-19T11:53:26.542764Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"                 ID   CNT_CHILDREN  AMT_INCOME_TOTAL     DAYS_BIRTH  \\\ncount  4.385570e+05  438557.000000      4.385570e+05  438557.000000   \nmean   6.022176e+06       0.427390      1.875243e+05  -15997.904649   \nstd    5.716370e+05       0.724882      1.100869e+05    4185.030007   \nmin    5.008804e+06       0.000000      2.610000e+04  -25201.000000   \n25%    5.609375e+06       0.000000      1.215000e+05  -19483.000000   \n50%    6.047745e+06       0.000000      1.607805e+05  -15630.000000   \n75%    6.456971e+06       1.000000      2.250000e+05  -12514.000000   \nmax    7.999952e+06      19.000000      6.750000e+06   -7489.000000   \n\n       DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE     FLAG_PHONE  \\\ncount  438557.000000    438557.0    438557.000000  438557.000000   \nmean    60563.675328         1.0         0.206133       0.287771   \nstd    138767.799647         0.0         0.404527       0.452724   \nmin    -17531.000000         1.0         0.000000       0.000000   \n25%     -3103.000000         1.0         0.000000       0.000000   \n50%     -1467.000000         1.0         0.000000       0.000000   \n75%      -371.000000         1.0         0.000000       1.000000   \nmax    365243.000000         1.0         1.000000       1.000000   \n\n          FLAG_EMAIL  CNT_FAM_MEMBERS  \ncount  438557.000000    438557.000000  \nmean        0.108207         2.194465  \nstd         0.310642         0.897207  \nmin         0.000000         1.000000  \n25%         0.000000         2.000000  \n50%         0.000000         2.000000  \n75%         0.000000         3.000000  \nmax         1.000000        20.000000  \n/n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 438557 entries, 0 to 438556\nData columns (total 18 columns):\n #   Column               Non-Null Count   Dtype  \n---  ------               --------------   -----  \n 0   ID                   438557 non-null  int64  \n 1   CODE_GENDER          438557 non-null  object \n 2   FLAG_OWN_CAR         438557 non-null  object \n 3   FLAG_OWN_REALTY      438557 non-null  object \n 4   CNT_CHILDREN         438557 non-null  int64  \n 5   AMT_INCOME_TOTAL     438557 non-null  float64\n 6   NAME_INCOME_TYPE     438557 non-null  object \n 7   NAME_EDUCATION_TYPE  438557 non-null  object \n 8   NAME_FAMILY_STATUS   438557 non-null  object \n 9   NAME_HOUSING_TYPE    438557 non-null  object \n 10  DAYS_BIRTH           438557 non-null  int64  \n 11  DAYS_EMPLOYED        438557 non-null  int64  \n 12  FLAG_MOBIL           438557 non-null  int64  \n 13  FLAG_WORK_PHONE      438557 non-null  int64  \n 14  FLAG_PHONE           438557 non-null  int64  \n 15  FLAG_EMAIL           438557 non-null  int64  \n 16  OCCUPATION_TYPE      304354 non-null  object \n 17  CNT_FAM_MEMBERS      438557 non-null  float64\ndtypes: float64(2), int64(8), object(8)\nmemory usage: 60.2+ MB\nNone\n/n\n             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n438546  6839890           F            N               N             0   \n438547  6839917           F            N               Y             0   \n438548  6839936           M            Y               Y             1   \n438549  6840098           F            N               Y             0   \n438550  6840100           F            N               Y             0   \n438551  6840102           F            N               Y             0   \n438552  6840104           M            N               Y             0   \n438553  6840222           F            N               N             0   \n438554  6841878           F            N               N             0   \n438555  6842765           F            N               Y             0   \n438556  6842885           F            N               Y             0   \n\n        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n438546          157500.0             Pensioner  Secondary / secondary special   \n438547          180000.0             Pensioner               Higher education   \n438548          135000.0               Working  Secondary / secondary special   \n438549          135000.0             Pensioner  Secondary / secondary special   \n438550          135000.0             Pensioner  Secondary / secondary special   \n438551          135000.0             Pensioner  Secondary / secondary special   \n438552          135000.0             Pensioner  Secondary / secondary special   \n438553          103500.0               Working  Secondary / secondary special   \n438554           54000.0  Commercial associate               Higher education   \n438555           72000.0             Pensioner  Secondary / secondary special   \n438556          121500.0               Working  Secondary / secondary special   \n\n          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n438546  Single / not married  House / apartment      -22551         365243   \n438547               Married  House / apartment      -10966          -2704   \n438548               Married  House / apartment      -12569          -2095   \n438549             Separated  House / apartment      -22717         365243   \n438550             Separated  House / apartment      -22717         365243   \n438551             Separated  House / apartment      -22717         365243   \n438552             Separated  House / apartment      -22717         365243   \n438553  Single / not married  House / apartment      -15939          -3007   \n438554  Single / not married       With parents       -8169           -372   \n438555               Married  House / apartment      -21673         365243   \n438556               Married  House / apartment      -18858          -1201   \n\n        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n438546           1                0           0           0             NaN   \n438547           1                0           0           0             NaN   \n438548           1                0           0           0        Laborers   \n438549           1                0           0           0             NaN   \n438550           1                0           0           0             NaN   \n438551           1                0           0           0             NaN   \n438552           1                0           0           0             NaN   \n438553           1                0           0           0        Laborers   \n438554           1                1           0           0     Sales staff   \n438555           1                0           0           0             NaN   \n438556           1                0           1           0     Sales staff   \n\n        CNT_FAM_MEMBERS  \n438546              1.0  \n438547              2.0  \n438548              3.0  \n438549              1.0  \n438550              1.0  \n438551              1.0  \n438552              1.0  \n438553              1.0  \n438554              1.0  \n438555              2.0  \n438556              2.0  \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}